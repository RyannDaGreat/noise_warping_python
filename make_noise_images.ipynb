{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effb73c0-42e6-459c-8a62-e7fcf9a20f1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T05:55:34.804611Z",
     "iopub.status.busy": "2024-07-09T05:55:34.804312Z",
     "iopub.status.idle": "2024-07-09T05:55:34.917940Z",
     "shell.execute_reply": "2024-07-09T05:55:34.917461Z",
     "shell.execute_reply.started": "2024-07-09T05:55:34.804588Z"
    }
   },
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "from rp import *\n",
    "\n",
    "channel = JupyterDisplayChannel()\n",
    "channel.display()\n",
    "\n",
    "mask_channel = JupyterDisplayChannel()\n",
    "mask_channel.display()\n",
    "\n",
    "\n",
    "textured_model_channel = JupyterDisplayChannel()\n",
    "textured_model_channel.display()\n",
    "\n",
    "\n",
    "text_channel = JupyterDisplayChannel()\n",
    "text_channel.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae73db9-723f-4690-87dc-43b41e6176af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T05:55:34.919492Z",
     "iopub.status.busy": "2024-07-09T05:55:34.919224Z"
    }
   },
   "outputs": [],
   "source": [
    "import noise_warping as nw\n",
    "import torch\n",
    "from icecream import ic\n",
    "\n",
    "if \"device\" not in vars():\n",
    "    device = select_torch_device(prefer_used=True)\n",
    "\n",
    "# uvl_image= rp.load_image('/root/CleanCode/Projects/deepfloyd_init_test/blender/BlenderOutputKevinSpinner/UV_Label_Exr/Image0155.exr',use_cache=True)\n",
    "# uvl_image = rp.resize_image_to_fit(uvl_image,256,256,interp='nearest')\n",
    "# texture_image = rp.load_image('https://upload.wikimedia.org/wikipedia/en/7/7d/Lenna_%28test_image%29.png',use_cache=True)\n",
    "\n",
    "\n",
    "if \"texture_image\" not in vars():\n",
    "    tic()\n",
    "    # texture_image=get_checkerboard_image(height=512*3,width=512*3)\n",
    "    # texture_image = rp.as_float_image(rp.as_rgb_image(texture_image))\n",
    "    # texture_image[:]=-1\n",
    "    # texture_image=rp.as_torch_image(texture_image)\n",
    "    # texture_image=torch.randn_like(texture_image)\n",
    "    texture_image = torch.randn(4, 20000, 20000)\n",
    "    # noise_backdrop = torch.randn(4, 40000, 40000)  # Not too big\n",
    "    texture_image = texture_image.to(device)\n",
    "    # noise_backdrop = noise_backdrop.to(device)\n",
    "    # texture_image=texture_image.to(device)\n",
    "    ptoc()\n",
    "\n",
    "# texture_image= load_image('/Users/ryan/Downloads/KevinSpinner/frame_0002_point-cloud_geo_geo-retexture.jpg')\n",
    "\n",
    "\n",
    "if not 'background_torch_randn' in vars():\n",
    "    @memoized\n",
    "    def background_torch_randn(dims):\n",
    "        return torch.randn(dims).to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if __name__==\"__main__\":\n",
    "def warped_noise_from_uvl_path(path):\n",
    "    uvl_image = rp.load_image(path, use_cache=True)\n",
    "    F=3;uvl_image = cv_resize_image(uvl_image, (240 * F + 1, 135 * F + 1), \"nearest\")\n",
    "    # F=6;uvl_image = cv_resize_image(uvl_image, (114 * F + 1, 64 * F + 1), \"nearest\")\n",
    "\n",
    "    uvl_image[:,:,0] *= uvl_image[:,:,2] == 0 #Where blue, destroy UV so we don't repeat anything...\n",
    "    uvl_image[:,:,1] *= uvl_image[:,:,2] == 0 #Where blue, destroy UV so we don't repeat anything...\n",
    "\n",
    "    uvl_image = rp.as_torch_image(uvl_image).to(device)\n",
    "\n",
    "    out = nw.uv_mapping_discretized(uv_image = uvl_image, tex_image=texture_image, w=20, debug_plot=False)\n",
    "\n",
    "    out.noisewarp = out.ryan_filter*out.area**.5\n",
    "\n",
    "    std_mea = out.noisewarp.flatten()\n",
    "    std_mea = std_mea[std_mea!=0]\n",
    "\n",
    "    #True where we should include the static background noise\n",
    "    background_mask_matrix = out.area[0] == 0\n",
    "    foreground_mask_matrix = 1-background_mask_matrix.float()\n",
    "\n",
    "    rp.display_image(\n",
    "        rp.horizontally_concatenated_images(\n",
    "            rp.as_numpy_image(out.noisewarp / 10 + 0.5),\n",
    "            rp.as_numpy_array(background_mask_matrix),\n",
    "        )\n",
    "    )\n",
    "    ic(\n",
    "        out.noisewarp.min(),\n",
    "        out.noisewarp.max(),\n",
    "        out.noisewarp.mean(),\n",
    "        out.noisewarp.std(),\n",
    "        std_mea.std(),\n",
    "    )\n",
    "\n",
    "\n",
    "    mask_channel.update(rp.as_rgb_image(rp.as_numpy_array(foreground_mask_matrix)))\n",
    "\n",
    "    # noisewarp_with_noise_background = background_noise * background_mask_matrix[None] + out.noisewarp\n",
    "\n",
    "    # Variance-preserving downsample\n",
    "    lowres_noisewarp_sum = torch.nn.functional.avg_pool2d(out.noisewarp[None], kernel_size=F, stride=F)[0]\n",
    "    lowres_noisewarp_sum = lowres_noisewarp_sum * F * F #Turn the avg into a sum\n",
    "\n",
    "    # Be nice to the cracks and seams...\n",
    "    lowres_foreground_area_matrix = torch.nn.functional.avg_pool2d(foreground_mask_matrix[None,None], kernel_size=F, stride=F)[0,0]\n",
    "    lowres_foreground_area_matrix = lowres_foreground_area_matrix * F**2 #Adjust variance\n",
    "\n",
    "    lowres_noisewarp = lowres_noisewarp_sum / lowres_foreground_area_matrix[None] ** .5\n",
    "    lowres_noisewarp = lowres_noisewarp.nan_to_num()\n",
    "\n",
    "    background_noise = background_torch_randn(lowres_noisewarp.shape)\n",
    "\n",
    "    lowres_noisewarp = lowres_noisewarp + (lowres_foreground_area_matrix[None] == 0) * background_noise\n",
    "\n",
    "    \n",
    "    #TODO: Scale down a large texture-mapped noise and then bin them and weight it properly...only after that should you add the background noise\n",
    "    #That way we can get as much consistency as possible, fill in as much of those pesky seams as we can...\n",
    "\n",
    "    output_noise = rp.as_numpy_image(lowres_noisewarp)\n",
    "    text_channel.grid_update([[x] for x in [\n",
    "        \" \".join(map(str,(\"STD MEA STD \",std_mea.std(),))),\n",
    "        # \" \".join(map(str,(\"OUTSTD \",noisewarp_with_noise_background.std(),))),\n",
    "        # \" \".join(map(str,(\"OUTMEAN \",noisewarp_with_noise_background.mean(),))),\n",
    "        \" \".join(map(str,(\"OUTNOISE_STD \",output_noise.std(),))),\n",
    "        \" \".join(map(str,(\"OUTNOISE_STD \",output_noise.shape,))),\n",
    "    ]])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    return output_noise\n",
    "\n",
    "\n",
    "# ans = process_uvl_path('/root/CleanCode/Projects/deepfloyd_init_test/blender/BlenderOutputKevinSpinner/UV_Label_Exr/Image0155.exr')\n",
    "# display_image(ans/10+.5)\n",
    "\n",
    "# warped_noise_image / 10 + .5\n",
    "from IPython.display import clear_output\n",
    "\n",
    "output_folder = make_directory(\n",
    "    get_unique_copy_path(\"noisewarp_outputs/KevinSpinnerAlignedFloored\")\n",
    ")\n",
    "\n",
    "ic.disable()\n",
    "input_paths = sorted(\n",
    "    rp_glob(\n",
    "        \"/root/CleanCode/Projects/deepfloyd_init_test/blender/BlenderOutputKevinSpinner/UV_Label_Exr/*.exr\"\n",
    "    )\n",
    ")\n",
    "input_paths = sorted(\n",
    "    rp_glob(\n",
    "        \"/root/CleanCode/Projects/deepfloyd_init_test/blender/ProperSpinnerJul1/BlenderOutputKevinSpinner/UV_Label_Exr/*.exr\"\n",
    "    )\n",
    ")[::-1]\n",
    "\n",
    "for index,input_path in enumerate(input_paths):\n",
    "    warped_noise_image = warped_noise_from_uvl_path(input_path)\n",
    "    clear_output()\n",
    "    output_path = path_join(output_folder, ('%05i'%index)+get_file_name(input_path))\n",
    "    print(\"IN:\", input_path)\n",
    "    print(\"OUT:\", output_path)\n",
    "    # display_image(warped_noise_image)\n",
    "\n",
    "    saveable_image = warped_noise_image #/ 10 + 0.5\n",
    "    channel.update(rp.as_rgb_image(saveable_image))\n",
    "    # channel.update(rp.as_rgb_image(saveable_image))\n",
    "    run_as_new_thread(\n",
    "        save_image, saveable_image, output_path\n",
    "    )  # Quantization doesn't matter too much..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abe8307-9c0c-4473-b6e5-7de13dab5fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveable_image.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c33e2c-aa89-4c5d-86b2-853e914b5e3d",
   "metadata": {},
   "source": [
    "At http://ryan-burgert-controlnet-tests.workbench.prod.netflix.net:54545\n",
    "In /root/CleanCode/Projects/deepfloyd_init_test/noise_warping_python/noisewarp_outputs/KevinSpinner_copy16/*.exr\n",
    "Use this code to view noise:\n",
    "\n",
    "\"\"\"\n",
    "import rp\n",
    "import glob\n",
    "\n",
    "def glob_search(query: str, replacements: dict) -> list:\n",
    "    \"\"\"\n",
    "    Query is like \"/path/to/{x:05}/image_*/{y}.png\"\n",
    "    Replacements is like {\"x\":5,\"y\":100}\n",
    "    Returns a list of globbed paths\n",
    "    \"\"\"\n",
    "    query = query.format(**replacements)\n",
    "    paths = glob.glob(query)\n",
    "    paths = sorted(paths)\n",
    "    return paths\n",
    "\n",
    "@rp.memoized\n",
    "def load_image_bytes(path: str) -> bytes:\n",
    "    image = rp.load_image(path, use_cache=True)\n",
    "    # image = rp.resize_image_to_fit(image, height = 512,interp='area')\n",
    "    image = rp.rotate_image(image, 90)\n",
    "    title = '\\n'.join(path.split('/')[-3:])\n",
    "    image = rp.labeled_image(image, title, size=60)\n",
    "    image_bytes = rp.encode_image_to_bytes(image, 'png', quality=95)\n",
    "    return image_bytes\n",
    "\n",
    "    # return rp.file_to_bytes(path) #Just loads the file raw\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bd54e3-d11f-4503-8cd0-b3f3a950cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import AlgoNotes as nw\n",
    "import torch\n",
    "from icecream import ic\n",
    "\n",
    "if \"device\" not in vars():\n",
    "    device = select_torch_device(prefer_used=True)\n",
    "\n",
    "if \"kevin_texture_image\" not in vars():\n",
    "    kevin_texture_image = \"/root/CleanCode/Projects/deepfloyd_init_test/blender/frame_0002_point-cloud_geo_geo-retexture.1001.jpg\"\n",
    "    kevin_texture_image = as_torch_image(\n",
    "        as_float_image(as_rgb_image(load_image(kevin_texture_image)))\n",
    "    ).to(device)\n",
    "\n",
    "\n",
    "def textured_model_from_uvl_path(path):\n",
    "    uvl_image = rp.load_image(path, use_cache=True)\n",
    "\n",
    "    uvl_image = as_torch_image(uvl_image).to(device)\n",
    "\n",
    "    output = nw.uv_mapping_discretized(\n",
    "        uv_image=uvl_image, tex_image=kevin_texture_image, w=1, device=device\n",
    "    )\n",
    "    ic(texture_image.shape, output.ryan_filter.shape)\n",
    "\n",
    "    out_image = output.linear\n",
    "\n",
    "    is_blue = uvl_image[2, 1:, 1:][None] > 0\n",
    "    out_image = torch.maximum(is_blue, out_image)\n",
    "\n",
    "    out_image = as_numpy_image(out_image)\n",
    "    return out_image\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "output_folder = make_directory(\n",
    "    get_unique_copy_path(\"noisewarp_outputs/KevinSpinnerAlignedTextured\")\n",
    ")\n",
    "\n",
    "ic.disable()\n",
    "input_paths = sorted(\n",
    "    rp_glob(\n",
    "        \"/root/CleanCode/Projects/deepfloyd_init_test/blender/BlenderOutputKevinSpinner/UV_Label_Exr/*.exr\"\n",
    "    )\n",
    ")\n",
    "input_paths = sorted(\n",
    "    rp_glob(\n",
    "        \"/root/CleanCode/Projects/deepfloyd_init_test/blender/ProperSpinnerJul1/BlenderOutputKevinSpinner/UV_Label_Exr/*.exr\"\n",
    "    )\n",
    ")[::-1]\n",
    "for input_path in input_paths:\n",
    "    textured_model_image = textured_model_from_uvl_path(input_path)\n",
    "    clear_output()\n",
    "    output_path = path_join(output_folder, get_file_name(input_path))\n",
    "    print(\"IN:\", input_path)\n",
    "    print(\"OUT:\", output_path)\n",
    "    # display_image(warped_noise_image)\n",
    "\n",
    "    saveable_image = textured_model_image\n",
    "    textured_model_channel.update(saveable_image)\n",
    "    run_as_new_thread(\n",
    "        save_image, saveable_image, output_path\n",
    "    )  # Quantization doesn't matter too much..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cef00e0-759f-4037-b86b-08372e1d7b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "kevin_texture_image = as_torch_image(\n",
    "    as_float_image(as_rgb_image(load_image(kevin_texture_image)))\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb85c22-4c29-4b2e-8bd3-fe54bb657154",
   "metadata": {},
   "outputs": [],
   "source": [
    "del kevin_texture_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dc69d8-d825-4c76-b915-328b6be3a766",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python vaetuner",
   "language": "python",
   "name": "vaetuner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
